OCTOBER 30th Progress Report

Progress in Past 2 Weeks:

Alexis

Jackson
- Added water logic to environment (i.e., floor tile converts to water tile after agent moves off, agent drowns in water)
- Modified reward structure to make agent take longest path in environment
- Modularized code to make a reusable training agent that can be created for different learning algorithms
- Updated environment to properly represent new MDP (new X,Y, W-MASK, AVAIL-ACTION mask states).
- Converted environment and training to reflect how GridWorld in A2 is used (training uses state numbers provided by environment)

Kinjal

Lujain

Trista

Main Accomplishment: 
Established working MDP structure for environment that when train, accomplishes agent goals in proposal.
Created scalable training structure, so that we can begin to add and compare different learning algorithms

Goals for next 2 weeks: 
- Research and implement PPO and DQN learning algorithms (at least)
- Modify environment and training back to having q matrix based on internal state values (rather than generic state numbers)
- Look into (and modify environment and training accordingly), method to generalize training data to unseen levels.